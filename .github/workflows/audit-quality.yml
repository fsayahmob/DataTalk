name: Code Quality Audit

on:
  push:
    branches: [main, develop]
    paths:
      - 'backend/**'
      - 'frontend/**'
  pull_request:
    branches: [main, develop]
    paths:
      - 'backend/**'
      - 'frontend/**'
  schedule:
    - cron: '0 9 * * 1'  # Audit hebdomadaire lundi 9h UTC
  workflow_dispatch:
    inputs:
      fail_under:
        description: 'Score minimum requis (0-100)'
        required: false
        default: '70'

env:
  PYTHON_VERSION: '3.11'
  FAIL_UNDER: 70  # Score minimum requis

jobs:
  audit:
    runs-on: ubuntu-latest

    outputs:
      score: ${{ steps.audit.outputs.score }}
      grade: ${{ steps.audit.outputs.grade }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        working-directory: backend
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install ruff mypy pytest pytest-cov pytest-asyncio

      - name: Run audit script
        id: audit
        run: |
          # Exécuter l'audit et capturer le JSON
          python scripts/audit_score.py --json > audit_result.json 2>&1 || true

          # Extraire score et grade
          SCORE=$(cat audit_result.json | python -c "import sys,json; d=json.load(sys.stdin); print(d['score'])")
          GRADE=$(cat audit_result.json | python -c "import sys,json; d=json.load(sys.stdin); print(d['grade'])")

          echo "score=$SCORE" >> $GITHUB_OUTPUT
          echo "grade=$GRADE" >> $GITHUB_OUTPUT

          # Afficher le rapport lisible
          python scripts/audit_score.py

          # Sauvegarder pour artifacts
          cp audit_result.json ../audit_result.json

      - name: Upload audit report
        uses: actions/upload-artifact@v4
        with:
          name: audit-report
          path: audit_result.json
          retention-days: 90

      - name: Check score threshold
        run: |
          python scripts/audit_score.py --fail-under ${{ env.FAIL_UNDER }}

      - name: Create score badge
        if: github.ref == 'refs/heads/main'
        run: |
          SCORE=${{ steps.audit.outputs.score }}
          GRADE=${{ steps.audit.outputs.grade }}

          # Couleur selon le grade
          if [ "$GRADE" = "A" ]; then COLOR="brightgreen"
          elif [ "$GRADE" = "B" ]; then COLOR="green"
          elif [ "$GRADE" = "C" ]; then COLOR="yellow"
          elif [ "$GRADE" = "D" ]; then COLOR="orange"
          else COLOR="red"
          fi

          echo "Badge: Score $SCORE - Grade $GRADE - Color $COLOR"
          # Le badge peut être généré via shields.io ou stocké dans le repo

  # Job de notification si le score baisse
  notify-degradation:
    needs: audit
    runs-on: ubuntu-latest
    if: ${{ needs.audit.outputs.score < 70 || failure() }}

    steps:
      - name: Send email notification
        uses: dawidd6/action-send-mail@v3
        with:
          server_address: smtp.gmail.com
          server_port: 587
          username: ${{ secrets.SMTP_USERNAME }}
          password: ${{ secrets.SMTP_PASSWORD }}
          subject: "⚠️ Code Quality Alert - Score: ${{ needs.audit.outputs.score }}/100"
          to: ${{ secrets.ALERT_EMAIL }}
          from: "CI Bot <ci@talkdata.app>"
          body: |
            Code Quality Audit Report
            ========================

            Repository: ${{ github.repository }}
            Branch: ${{ github.ref_name }}
            Commit: ${{ github.sha }}

            Score: ${{ needs.audit.outputs.score }}/100
            Grade: ${{ needs.audit.outputs.grade }}

            ⚠️ Le score est passé sous le seuil de 70.

            Détails: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}

            ---
            Actions recommandées:
            1. Vérifier les erreurs ruff/mypy
            2. Augmenter la couverture de tests
            3. Corriger les warnings de sécurité

      - name: Post to Slack (optional)
        if: ${{ secrets.SLACK_WEBHOOK_URL != '' }}
        uses: slackapi/slack-github-action@v1
        with:
          payload: |
            {
              "text": "⚠️ Code Quality Alert",
              "blocks": [
                {
                  "type": "section",
                  "text": {
                    "type": "mrkdwn",
                    "text": "*Code Quality Score Dropped*\n\nScore: ${{ needs.audit.outputs.score }}/100 (Grade: ${{ needs.audit.outputs.grade }})\nRepo: ${{ github.repository }}\nBranch: ${{ github.ref_name }}"
                  }
                },
                {
                  "type": "actions",
                  "elements": [
                    {
                      "type": "button",
                      "text": { "type": "plain_text", "text": "View Details" },
                      "url": "${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"
                    }
                  ]
                }
              ]
            }
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
          SLACK_WEBHOOK_TYPE: INCOMING_WEBHOOK

  # Job de comparaison avec le score précédent (hebdomadaire)
  compare-scores:
    needs: audit
    runs-on: ubuntu-latest

    steps:
      - name: Download previous score
        uses: dawidd6/action-download-artifact@v3
        with:
          workflow: audit-quality.yml
          branch: main
          name: audit-report
          path: previous
        continue-on-error: true

      - name: Compare scores
        run: |
          CURRENT_SCORE=${{ needs.audit.outputs.score }}

          if [ -f previous/audit_result.json ]; then
            PREVIOUS_SCORE=$(cat previous/audit_result.json | python -c "import sys,json; d=json.load(sys.stdin); print(d['score'])")
            DIFF=$((CURRENT_SCORE - PREVIOUS_SCORE))

            echo "================================================"
            echo "  COMPARAISON HEBDOMADAIRE"
            echo "================================================"
            echo "Previous score: $PREVIOUS_SCORE"
            echo "Current score:  $CURRENT_SCORE"
            echo "Difference:     $DIFF"
            echo "================================================"

            if [ $DIFF -lt -5 ]; then
              echo "::error::Score dropped significantly by $DIFF points!"
            elif [ $DIFF -lt 0 ]; then
              echo "::warning::Score decreased by $DIFF points"
            elif [ $DIFF -gt 0 ]; then
              echo "::notice::Score improved by +$DIFF points!"
            else
              echo "Score unchanged"
            fi
          else
            echo "No previous score to compare (first run)"
          fi
